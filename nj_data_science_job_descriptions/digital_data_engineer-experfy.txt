Work with business teams to understand requirements, and translate them into technical needs Gather/organize large & complex data assets, and perform relevant analysis Ensure the quality of the data in coordination with Data Analysts and Data Scientists (peer validation) Propose and implement relevant data models for each business case Create data models and optimize queries performance Communicate results and findings in a structured way Partner with Product Owner and Data Analysts to prioritize the pipeline implementation plan Partner with Data Analysts and Data scientists to design pipelines relevant for business requirements Leverage existing or create new "standard data pipelines" within the company to bring value through business use cases Ensure best practices in data manipulation are enforced end-to-end Actively contribute to Data governance community Remains up to date on company's standards, industry practices and emerging technologies Experience working with a variety of cross-functional teams Good understanding of agile/scrum development processes and concepts Able to work in a fast-paced, constantly evolving environment and manage multiple priorities Pragmatic and capable of solving complex issues Service-oriented, flexible team player Attention to detail & technical intuition Excellent written, verbal, and interpersonal skills for executive level communication and collaboration Fluent in English (Other languages a plus) Bachelor's Degree or equivalent in in Computer Science, Engineering, or relevant field Experience with AWS cloud services (Azure & GCP a plus) Good knowledge of SQL and relational databases technologies/concepts Experience working with data models and query tuning Experience in Data warehousing solutions (Snowflake a plus) Experience in Integration Services (IICS, Tibco a plus) Working knowledge of scripting languages (Python, R a plus) Familiarity with Source Code Management Tools (GitHub a plus) Familiarity with Visualization Tools (PowerBI, Tableau a plus) Familiarity with Project Management Tools (JIRA, Confluence a plus) Familiarity with Service Management Tools (Service Now a plus) Experience working in life sciences/pharmaceutical industry is a plus Relevant cloud certifications (AWS, Azure, Snowflake, IICS) are a plus Experience on working within compliance (e.g.: quality, regulatory - data privacy, GxP, SOX) and cybersecurity requirements is a plus Mentoring and/or technology evangelism/advocacy experience Strong experience in automation tools and methodologies specifically using Gitlab, Github action, Terraform, Ansible Experience with programming languages such as Python, JSON, YAML, Shell Scripting Experience with backup system like Netbackup & CommVault Good knowledge of ServiceNow and monitoring tool such as Splunk, BPPM Experience with Real World Data (e,g, EHR, Claims) and standard data models (e,g, OMOP, FHIR) Experience using frameworks to create pipelines (e.g. Apache Airflow, Kedro)
